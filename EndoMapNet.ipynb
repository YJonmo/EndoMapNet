{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EndoMapNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOT2SOCa2bu5ojpc9sggvfr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LoN3hGSWRcXS"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyxuDd6Zup4e"},"source":["%%bash\n","MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n","MINICONDA_PREFIX=/usr/local\n","wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n","chmod +x $MINICONDA_INSTALLER_SCRIPT\n","./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MhhR4RNYuv-Z"},"source":["%cd /content/drive/MyDrive/\n","!mkdir -p EndoMapNet\n","%cd EndoMapNet/\n","!git init\n","!git clone https://github.com/YJonmo/EndoMapNet\n","%cd EndoMapNet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7xX8KiguzQ_"},"source":["######################## You could skip this as it uploads the pretrained model####################\n","#This is the pretrained model on 8000 images of a 3D printed knee. The resolution of the image is 256*256.\n","#The 8000 images may not be enough for achieving desirable results. More training maybe needed. \n","#It can be used for training your model or for demonstration of the output. \n","!gdown https://drive.google.com/u/1/uc?id=1J1MFm9tudt-YJWa6b32Whjb10na4sUgT&export=download\n","!mkdir -p PreTrained\n","!unzip PreTrained.zip -d PreTrained"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U53esLWsu1Xk"},"source":["%%bash\n","##################### This is a demo for training the network on the images ##################################\n","DATA_Folder=/content/drive/MyDrive/EndoMapNet/EndoMapNet/DataSets/\n","#now=$(date +\"%T\")\n","OUTPUT=TrainingFolder\n","mkdir -p $OUTPUT\n","Splits=3DPrintedKnee\n","weight=PreTrained\n","\n","python train.py --data_path $DATA_Folder --split $Splits  \\\n","\t--log_dir $OUTPUT --png --no_eval --dataset Custom \\\n","\t--height 256 --width 256 --batch_size 8 --frame_ids 0 2 \\\n","\t--pose_model_input all  --num_epochs 10 --use_stereo \\\n","  --load_weights_folder $weight \\\n","  --models_to_load pose_encoder encoder depth pose \\\n","\t--use_pose 1 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sal_8xFCu3zy"},"source":["%%bash \n","##################### This is a demo for predicting depth from images ##################################\n","Weight=./PreTrained  # or ./TrainingFolder/mdp/models/weights_XX \n","DATA_Folder=./DataSets/TestDepth\n","python test_simple.py --image_path $DATA_Folder --model_name $Weight "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fb-iJY_qY-r0"},"source":["import PIL.Image as pil\n","from matplotlib import pyplot as plt\n","image=pil.open('./DataSets/TestDepth/02050.png')\n","depth=pil.open('./DataSets/TestDepth/02050_depth.jpeg')\n","plt.imshow(image)\n","plt.title('Input image')\n","plt.figure()\n","plt.title('Guessed depth')\n","plt.imshow(depth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGWAUrOj4RcK"},"source":["%%bash\n","##################### This is a demo for predicting poses of a sequence if images ##################################\n","Splits='2020-09-18-14-03-36'\n","DATA_Folder=/content/drive/MyDrive/EndoMapNet/EndoMapNet/DataSets/\n","Weight=PreTrained\n","python evaluate.py --split $Splits  --load_weights_folder $Weight \\\n","  --png --dataset Custom --data_path $DATA_Folder \\\n","  --height 256 --width 256 --batch_size 1 --use_stereo --frame_ids  0 2 \\\n","  --pose_model_type separate_resnet --pose_model_input all \\\n","  --models_to_load pose pose_encoder --use_pose 1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MB9Uf7dO2fSd"},"source":["import numpy as np\n","Pose_Predicted='./PreTrained/poses_2020-09-18-14-03-36.npy'\n","Poses_3D = np.load(Pose_Predicted) \n","Poses_3D = Poses_3D.astype(np.float64) \n","\n","Pose_GroundTruth='./splits/2020-09-18-14-03-36/2020-09-18-14-03-36.txt'\n","Pose_file_E = open(Pose_GroundTruth, 'r')\n","\n","#Poses_3D_GLB = Poses_3D.copy() \n","No_ref_fram = 1 \n","FrameIndex = 1 #  \n","\n","\n","Poses_3D_GLB = np.zeros((int(np.shape(Poses_3D)[0]/No_ref_fram), 4, 4), np.float64) \n","Poses_3D_GLB[0,:,:] = np.eye(4) \n","Quat_GLB = np.zeros((int(np.shape(Poses_3D)[0]/No_ref_fram), 1, 4), np.float64) \n","Euler_GLB = np.zeros((int(np.shape(Poses_3D)[0]/No_ref_fram), 1, 3), np.float64) \n","ii = 1 \n","for i in range( FrameIndex , len(Poses_3D)-No_ref_fram, No_ref_fram): \n","    Poses_3D_GLB[ii,:,:] =  np.dot(Poses_3D[i-1,:,:],  Poses_3D_GLB[ii-1,:,:]) \n","    ii += 1 \n","    #print (i) \n","#plt.plot(np.squeeze(Poses_3D_GLB[1:, 0:3, 3])) \n","trans_weight = 1/np.array([1., 1., 1.])\n","\n","\n","Pose_Lines_E = Pose_file_E.readlines()\n","#Pose_E = np.zeros((len(Pose_Lines_E), 6), np.float64)\n","Pose_E_Orig = np.zeros((len(Pose_Lines_E), 6), np.float64)\n","Start = 3\n","for Index_Pose in range(len(Pose_Lines_E)):  \n","    Pose_E_temp = Pose_Lines_E[Index_Pose].split(' ')\n","    Pose_E_Orig[Index_Pose][0] = float(Pose_E_temp[Start]) #- Pose_quatr[0][0]\n","    Pose_E_Orig[Index_Pose][1] = float(Pose_E_temp[Start+1]) #- Pose_quatr[0][1]\n","    Pose_E_Orig[Index_Pose][2] = float(Pose_E_temp[Start+2]) #- Pose_quatr[0][2]\n","    Pose_E_Orig[Index_Pose][3] = float(Pose_E_temp[Start+3]) #- Pose_quatr[0][3]\n","    Pose_E_Orig[Index_Pose][4] = float(Pose_E_temp[Start+4]) #- Pose_quatr[0][4]\n","    Pose_E_Orig[Index_Pose][5] = float(Pose_E_temp[Start+5]) #- Pose_quatr[0][5]            \n","\n","plt.plot(Pose_E_Orig[:,:3] - np.mean(Pose_E_Orig[0:2,:3],0))\n","plt.title('GroundTruth Translation')\n","plt.figure()\n","plt.plot(np.squeeze(Poses_3D_GLB[1:, 0:3, 3]))\n","plt.title('Predicted Translation')\n","plt.show()"],"execution_count":null,"outputs":[]}]}